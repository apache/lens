<?xml version="1.0"?>
<!--

    Licensed to the Apache Software Foundation (ASF) under one
    or more contributor license agreements.  See the NOTICE file
    distributed with this work for additional information
    regarding copyright ownership.  The ASF licenses this file
    to you under the Apache License, Version 2.0 (the
    "License"); you may not use this file except in compliance
    with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing,
    software distributed under the License is distributed on an
    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    KIND, either express or implied.  See the License for the
    specific language governing permissions and limitations
    under the License.

-->
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>lens.query.enable.persistent.resultset</name>
    <value>false</value>
    <description>Whether to enable persistent resultset for queries. When enabled,
      server will fetch results from driver, custom format them if any and store in
      a configured location. The file name of query output is queryhandle-id, with
      configured extensions
    </description>
  </property>

  <property>
    <name>lens.query.result.parent.dir</name>
    <value>file:///tmp/lensreports</value>
    <description>The directory for storing persisted result of query. This
      directory should exist and should have writable permissions by lens server
    </description>
  </property>

  <property>
    <name>lens.query.add.insert.overwrite</name>
    <value>true</value>
    <description>Prefix query with insert overwrite clause if the query is persistent.
      User can disable if user gave the clause himself.
    </description>
  </property>

  <property>
    <name>lens.query.enable.persistent.resultset.indriver</name>
    <value>true</value>
    <description>Whether the result should be persisted by driver. Currently only
      HiveDriver persists the results in a HDFS location.
    </description>
  </property>

  <property>
    <name>lens.query.result.output.dir.format</name>
    <value></value>
    <description>The format of the output if result is persisted in hdfs. The format
      should be expressed in HQL.
    </description>
  </property>

  <property>
    <name>lens.query.hdfs.output.path</name>
    <value>hdfsout</value>
    <description>The directory under the parent result directory, in which HiveDriver
      will persist the results, if persisting by driver is enabled. This directory
      should exist and should have world writable permissions sothat all users will
      be able put query outputs here.
    </description>
  </property>

  <property>
    <name>lens.query.output.formatter</name>
    <value></value>
    <description>The query result output formatter for the query. If no value is
      specified, then org.apache.lens.lib.query.FileSerdeFormatter will be used to
      format in-memory result sets, org.apache.lens.lib.query.FilePersistentFormatter
      will be used to format driver persisted result sets.
    </description>
  </property>

  <property>
    <name>lens.query.result.output.serde</name>
    <value>org.apache.lens.lib.query.CSVSerde</value>
    <description>The default serde class name that should be used by
      org.apache.lens.lib.query.FileSerdeFormatter for formatting the output
    </description>
  </property>

  <property>
    <name>lens.query.output.file.extn</name>
    <value>.csv</value>
    <description>The extension name for the persisted query output file. If
      file is compressed, the extension from compression codec will be appended to
      this extension.
    </description>
  </property>

  <property>
    <name>lens.query.output.charset.encoding</name>
    <value>UTF-8</value>
    <description>The charset encoding for formatting query result. It supports
      all the encodings supported by java.io.OutputStreamWriter.
    </description>
  </property>

  <property>
    <name>lens.query.output.enable.compression</name>
    <value>false</value>
    <description>Whether to compress the query result output</description>
  </property>

  <property>
    <name>lens.query.output.compression.codec</name>
    <value>org.apache.hadoop.io.compress.GzipCodec</value>
    <description>The codec used to compress the query output, if compression is
      enabled
    </description>
  </property>

  <property>
    <name>lens.query.output.write.header</name>
    <value>false</value>
    <description>Whether to write header as part of query result formatting. When
      enabled the user given header will be added in case of driver persisted results,
      and column names chosen will be added as header for in-memory results.
    </description>
  </property>

  <property>
    <name>lens.query.output.header</name>
    <value></value>
    <description>The value of custom header that should be written, if any. If no
      value column names will be used as header.
    </description>
  </property>

  <property>
    <name>lens.query.output.write.footer</name>
    <value>false</value>
    <description>Whether to write footer as part of query result. When enabled,
      total number of rows will be written as part of header.
    </description>
  </property>

  <property>
    <name>lens.query.output.footer</name>
    <value></value>
    <description>The value of custom footer that should be written, if any. This
      footer will be added in formatting driver persisted results.
    </description>
  </property>

  <property>
    <name>lens.query.result.size.format.threshold</name>
    <value>10737418240</value>
    <description>The maximum allowed size of the query result. If exceeds, no
      server side formatting would be done.
    </description>
  </property>

  <property>
    <name>lens.query.result.split.multiple</name>
    <value>false</value>
    <description>Whether to split the result into multiple files. If enabled,
      each file will be restricted to max rows configured. All the files will be
      available as zip.
    </description>
  </property>

  <property>
    <name>lens.query.result.split.multiple.maxrows</name>
    <value>100000</value>
    <description>The maximum number of rows allowed in each file, when splitting
      the result into multiple files is enabled.
    </description>
  </property>

  <property>
    <name>lens.query.result.fs.read.url</name>
    <value></value>
    <description>Http read URL for FileSystem on which result is present, if available.
      For example webhdfs as http read url should http://host:port/webhdfs/v1. Currently
      we support only webhdfs url as the http url for HDFS file system
    </description>
  </property>

  <property>
    <name>lens.query.result.email.cc</name>
    <value></value>
    <description>When query ends, the result/failure reason will be sent to
      the user via email. The mail would be cc'ed to the addresses provided
      in this field.
    </description>
  </property>

  <property>
    <name>lens.query.enable.mail.notify</name>
    <value>false</value>
    <description>When a query ends, whether to notify the submitter by mail or not.</description>
  </property>

  <property>
    <name>lens.query.enable.metrics.per.query</name>
    <value>false</value>
    <description>Generates gauge metrics for each query to measure time taken with unique id appended for each query.
    Should be enabled only for performance measurements. Should not be enabled in day to day production environment.
    </description>
  </property>

  <property>
    <name>lens.query.prefetch.inmemory.resultset</name>
    <value>true</value>
    <description>When set to true, specified number of rows of result set will be pre-fetched if the result set is of
    type InMemoryResultSet and query execution is not asynchronous i.e. query should be launched with
    operation as EXECUTE_WITH_TIMEOUT.
    Suggested usage of this property: It can be used by client to stream as well as persist results in server for
    queries that finish fast and produce results with fewer rows (should be less than number of rows pre-fetched).
    Note that the results are streamed to the client early, without waiting for persistence to finish.
    Default value of this property is true.
    </description>
  </property>

  <property>
    <name>lens.query.prefetch.inmemory.resultset.rows</name>
    <value>100</value>
    <description>Specifies the number of rows to pre-fetch when lens.query.prefetch.inmemory.resultset is set to true.
    Default value is 100 rows.
    </description>
  </property>

  <!--  properties for session -->
  <property>
    <name>lens.session.aux.jars</name>
    <value></value>
    <description>List of comma separated jar paths, which will added to the session</description>
  </property>

  <property>
    <name>lens.session.cluster.user</name>
    <value></value>
    <description>Session level config which will determine which cluster user will access hdfs</description>
  </property>
  <property>
    <name>lens.session.loggedin.user</name>
    <value></value>
    <description>The username used to log in to lens. e.g. LDAP user</description>
  </property>


  <!-- properties for metastore client -->
  <property>
    <name>hive.metastore.uris</name>
    <value></value>
    <description>The hive metastore server URI that the lens server is talking to</description>
  </property>

  <property>
    <name>hive.metastore.connect.retries</name>
    <value>5</value>
    <description>Number of retries while opening a connection to metastore</description>
  </property>

  <property>
    <name>hive.metastore.failure.retries</name>
    <value>3</value>
    <description>Number of call retries when Hive Metastore calls fail with Thrift errros</description>
  </property>

  <property>
    <name>hive.metastore.client.connect.retry.delay</name>
    <value>1</value>
    <description>Number of seconds for the client to wait between consecutive connection attempts</description>
  </property>

  <property>
    <name>hive.metastore.client.socket.timeout</name>
    <value>20</value>
    <description>MetaStore Client socket timeout in seconds</description>
  </property>

  <property>
    <name>hive.metastore.batch.retrieve.max</name>
    <value>100</value>
    <description>Maximum number of objects (tables/partitions) can be retrieved from metastore in one batch. The higher
      the number, the less the number of round trips is needed to the Hive metastore server, but it may also cause
      higher memory requirement at the client side.
    </description>
  </property>

  <property>
    <name>hive.metastore.batch.retrieve.table.partition.max</name>
    <value>500</value>
    <description>Maximum number of table partitions that metastore internally retrieves in one batch.</description>
  </property>

  <!-- query params -->

  <property>
    <name>lens.cube.query.disable.auto.join</name>
    <value>false</value>
    <description>Tells whether to disable automatic resolution of join conditions between tables involved.
      To enable automatic resolution, this value should be false.
    </description>
  </property>

  <property>
    <name>lens.cube.query.disable.aggregate.resolver</name>
    <value>false</value>
    <description>Tells whether to disable automatic resolution of aggregations for measures in a cube.
      To enable automatic resolution, this value should be false.
    </description>
  </property>

  <property>
    <name>lens.cube.query.promote.select.togroupby</name>
    <value>true</value>
    <description>Tells whether to promote select expressions which is not inside any aggregate, to be promoted to
      groupby clauses, if they are already not part of groupby clauses.
      To enable automatic promotion, this value should be true.
    </description>
  </property>

  <property>
    <name>lens.cube.query.fail.if.data.partial</name>
    <value>true</value>
    <description>Whether to fail the query of data is partial</description>
  </property>

  <property>
    <name>lens.session.metastore.exclude.cubetables.from.nativetables</name>
    <value>true</value>
    <description>Exclude cube related tables when fetching native tables</description>
  </property>

</configuration>
