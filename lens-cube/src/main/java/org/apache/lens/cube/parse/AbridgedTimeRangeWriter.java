/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.lens.cube.parse;

import org.apache.commons.lang.StringUtils;
import org.apache.hadoop.hive.ql.parse.SemanticException;

import java.util.*;

/**
 * Collapses the time range filters using IN operators
 */
public class AbridgedTimeRangeWriter implements TimeRangeWriter {
  /**
   * Return IN clause for the partitions selected in the cube query
   * @param cubeQueryContext
   * @param tableName
   * @param parts
   * @return
   * @throws SemanticException
   */
  @Override
  public String getTimeRangeWhereClause(CubeQueryContext cubeQueryContext,
                                        String tableName,
                                        Set<FactPartition> parts) throws SemanticException {
    if (parts == null || parts.isEmpty()) {
      return "";
    }

    // Collect partition specs by column in a map
    // All filters which contain only a single column will be combined in an IN operator clause
    // This clause will be ORed with filters which contain multiple columns.
    Map<String, List<String>> partFilterMap = new HashMap<String, List<String>>();
    List<String> allTimeRangeFilters = new ArrayList<String>();

    for (FactPartition factPartition : parts) {
      String filter = TimeRangeUtils.getTimeRangePartitionFilter(factPartition, cubeQueryContext, tableName);
      if (filter.contains("AND")) {
        allTimeRangeFilters.add(new StringBuilder("(").append(filter).append(")").toString());
      } else {
        extractColumnAndCondition(filter, partFilterMap);
      }
    }

    List<String> inClauses = new ArrayList<String>(partFilterMap.size());
    for (String column : partFilterMap.keySet()) {
      String clause =
        new StringBuilder("(").append(StringUtils.join(partFilterMap.get(column), ",")).append(")").toString();
      inClauses.add(column + " IN " + clause);
    }

    allTimeRangeFilters.add(StringUtils.join(inClauses, " AND "));
    return StringUtils.join(allTimeRangeFilters, " OR ");
  }

  // This takes the output of filter generated by TimeRangeUtils.getTimeRangePartitionFilter
  // splits the filters by column names and filters are collected by column name in the
  // map passed as argument
  private void extractColumnAndCondition(String token, Map<String, List<String>> partFilterMap) {
    token = token.trim();

    String[] subTokens = StringUtils.split(token, '=');

    String column = subTokens[0].trim();
    String filterValue = subTokens[1].trim();

    List<String> filterValues = partFilterMap.get(column);

    if (filterValues == null) {
      filterValues = new ArrayList<String>();
      partFilterMap.put(column, filterValues);
    }

    filterValues.add(filterValue);
  }
}
